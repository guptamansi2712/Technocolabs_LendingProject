# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eIhD5kb4NLhQalqenqG3Zsfuef7Yvk9R

# Importing Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# % matplotlib inline

"""# Loading csv datafile"""

df=pd.read_csv('/content/drive/MyDrive/Lending_Club_Loan_approval_Optimization.csv',index_col=[0])

"""# Checking Dataset loaded"""

df.tail(20).head()

"""# Checking Shape Of dataframe"""

df.shape

"""# Checking for duplicates """

df.duplicated().sum()

"""# Dropping Duplicates"""

df=df.drop_duplicates()

df.head()

"""# ScatterPlot-Amount Requested Vs Risk Score"""

sns.scatterplot(x="Risk_Score",y="Amount Requested",data=df,legend='auto')

"""# HeatMap"""

corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(10,10))
#plot heat map
g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap="RdYlGn")

"""# Splitting independent and dependent features and forming array"""

X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values

X

y

"""# Checking for balanced Data"""

sns.countplot(y)

"""# Splitting into train and test set"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 101)

X_train

"""# Performing standardization"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train

"""# Making Gradient Boost model"""

from sklearn.ensemble import GradientBoostingClassifier
classifier=GradientBoostingClassifier(random_state=101,n_estimators=200,learning_rate=0.05)
classifier.fit(X_train,y_train)

"""# Predicting values of x_test"""

y_pred=classifier.predict(X_test)

"""# Making Classification report"""

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""# Confusion Matrix"""

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test,y_pred))

"""## Making Pickle File"""

import pickle
pickle.dump(classifier, open('model.pkl','wb'))

model = pickle.load(open('model.pkl','rb'))
print(model.predict([[3600.0,677.0, 5.91,10]]))